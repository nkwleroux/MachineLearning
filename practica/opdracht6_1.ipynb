{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the downloaded mnist dataset from data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data('../mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the training dataset\n",
    "# Expected: 60000, 28, 28\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the test dataset\n",
    "# Expected: 10000, 28, 28\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data of the first trainings image (28 X 28 array).\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d4fdb63fc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the first image of the trainingsset in grayscale.\n",
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the two-dimensional (28 X 28) array's to a one-dimensional (784) array.\n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the training dataset\n",
    "# Expected: 60000, 784, because it is reshaped\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of the test dataset\n",
    "# Expected: 10000, 784, because it is reshaped\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value type of the dataset from int to float32\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Divide all values by 255.0, so they will be between 0.0 and 1.0\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data of the first trainings image.\n",
    "# Expected: 784 values between 0.0 and 1.0\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_train and y_test to binary class matrices.\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first value of y_train\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first matrix of y_train\n",
    "y_train_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of y_train_cat\n",
    "# Expected 60000, 10, because of categorisation\n",
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of y_test_cat\n",
    "# Expected 10000, 10, because of categorisation\n",
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add dense layer 1 with 512 neurons and a 28 X 28 input.\n",
    "# ReLU activation function is used. Formula: f(x) = max(0, x); \n",
    "# According to the formula: The function returns 0 if it receives any negative input, but for any positive input, it returns that value back.\n",
    "# In other words: It gives an output that has a range from 0 to infinity.\n",
    "model.add(Dense(512, input_dim=28*28, activation='relu'))\n",
    "\n",
    "# Add dense layer 2 with 256 neurons. ReLU activation function is used.\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add dense layer 3 with 128 neurons. ReLU activation function is used.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add dense layer 4 with 32 neurons. ReLu activation function is used.\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add dense layer 5 with 10 neurons. Softmax activation function is used in de output layer.\n",
    "#  The softmax activation function calculates the relative probabilities. Softmax is popularly used for multiclass classification problems.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Config the model with losses and matrics with model.compile.\n",
    "# loss = 'categorical_crossentropy': Computes the crossentropy loss between the labels and predictions.\n",
    "# optimizer = 'rmsprop':  Maintains a moving average of the gradients and uses that average to extimate the variance.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - 19s 8ms/step - loss: 0.6288 - accuracy: 0.8001 - val_loss: 0.1483 - val_accuracy: 0.9546\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.1190 - accuracy: 0.9633 - val_loss: 0.1220 - val_accuracy: 0.9627\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0717 - accuracy: 0.9787 - val_loss: 0.1121 - val_accuracy: 0.9675\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.1101 - val_accuracy: 0.9711\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.1639 - val_accuracy: 0.9632\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.1268 - val_accuracy: 0.9718\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.1180 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.1299 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.1516 - val_accuracy: 0.9729\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.1497 - val_accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Train the model with model.fit().\n",
    "    # batch_size = number of samples per gradient update.\n",
    "    # epochs = number of epochs to train the model. An epoch is an iteration over the entire x and y data provided.\n",
    "    # verbose = Verbosity mode 0 = silent, 1 = progress bar, 2 - one line per epoch.\n",
    "    # validation_split = Data on which to evaluate the loss and any model metrics at the end of each epoch.\n",
    "h = model.fit(X_train, y_train_cat, batch_size=128, epochs=10, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy of every epoch.\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1321 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9771000146865845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the loss value & metrics values for the model in test mode.\n",
    "test_accuracy = model.evaluate(X_test, y_test_cat)[1]\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# This layer creates a concolutional kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "# Parameters: Conv2D(filters, kernel_size, input_shape):\n",
    "    # filters: the number of output filters in the convolution\n",
    "    # kernel_size: A tuple of 2 integers, specifying the height and width of the convolution window. --> 3 X 3 kernel\n",
    "    # input_shape = (channels, rows, cols) --> 28 X 28 image\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "\n",
    "# This layer downsamples the input along its spatial dimensions (heigt and width) by taking the maximum value over and input\n",
    "# window for each channel of the input.\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# This applies an activation function to an output.\n",
    "# ReLU activation function is used. See explenation of ReLU above.\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# This layer flattens the input. It does not affect the batch size\n",
    "# Example: input = (10, 64) --> output = 640\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 128 neutrons and the activation function ReLU.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add a dense layer with 10 neutrons and the activation function softmax is used in the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Config the model with losses and matrics with model.compile.\n",
    "# loss = 'categorical_crossentropy': Computes the crossentropy loss between the labels and predictions.\n",
    "# optimizer = 'rmsprop':  Maintains a moving average of the gradients and uses that average to extimate the variance.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print a string summary of the model: layers (type), output shapes and params\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "329/329 [==============================] - 10s 24ms/step - loss: 0.5118 - accuracy: 0.8378 - val_loss: 0.1125 - val_accuracy: 0.9675\n",
      "Epoch 2/2\n",
      "329/329 [==============================] - 8s 24ms/step - loss: 0.0851 - accuracy: 0.9757 - val_loss: 0.0758 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d4ff0e5508>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with model.fit().\n",
    "    # batch_size = number of samples per gradient update --> 128.\n",
    "    # epochs = number of epochs to train the model. An epoch is an iteration over the entire x and y data provided --> 2.\n",
    "    # verbose = Verbosity mode 0 = silent, 1 = progress bar, 2 - one line per epoch --> 1.\n",
    "    # validation_split = Data on which to evaluate the loss and any model metrics at the end of each epoch --> 0.3.\n",
    "model.fit(X_train, y_train_cat, batch_size=128,\n",
    "          epochs=2, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0639830231666565, 0.978600025177002]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the loss value & metrics values for the model in test mode.\n",
    "model.evaluate(X_test, y_test_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
